"use strict";(self.webpackChunkcmcs_docs=self.webpackChunkcmcs_docs||[]).push([[880],{4137:(e,t,n)=>{n.d(t,{Zo:()=>l,kt:()=>d});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},i=Object.keys(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var c=r.createContext({}),p=function(e){var t=r.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},l=function(e){var t=p(e.components);return r.createElement(c.Provider,{value:t},e.children)},m="mdxType",g={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},u=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,c=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),m=p(n),u=a,d=m["".concat(c,".").concat(u)]||m[u]||g[u]||i;return n?r.createElement(d,o(o({ref:t},l),{},{components:n})):r.createElement(d,o({ref:t},l))}));function d(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,o=new Array(i);o[0]=u;var s={};for(var c in t)hasOwnProperty.call(t,c)&&(s[c]=t[c]);s.originalType=e,s[m]="string"==typeof e?e:a,o[1]=s;for(var p=2;p<i;p++)o[p]=n[p];return r.createElement.apply(null,o)}return r.createElement.apply(null,n)}u.displayName="MDXCreateElement"},9992:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>o,default:()=>g,frontMatter:()=>i,metadata:()=>s,toc:()=>p});var r=n(7462),a=(n(7294),n(4137));const i={slug:"Prompt_Engineering",title:"Prompt Engineering",authors:"cmgchess",tags:["PromptEngineering"]},o="Prompt Engineering",s={permalink:"/cmcs-docs/blog/Prompt_Engineering",editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2023-04-18.md",source:"@site/blog/2023-04-18.md",title:"Prompt Engineering",description:"The recent advances in language models have led to remarkable improvements in various NLP tasks, such as text generation, summarization, question answering, and sentiment analysis. However, even state-of-the-art language models like GPT-3 require massive amounts of training data and compute resources to achieve their impressive performance. In this context, prompt engineering is a promising approach that can significantly improve the efficiency and effectiveness of language models for specific tasks.",date:"2023-04-18T00:00:00.000Z",formattedDate:"April 18, 2023",tags:[{label:"PromptEngineering",permalink:"/cmcs-docs/blog/tags/prompt-engineering"}],readingTime:1.66,hasTruncateMarker:!0,authors:[{name:"Chathulanka Gamage",title:"Lingua maintainer",url:"https://github.com/cmgchess",imageURL:"https://avatars.githubusercontent.com/u/61736812?v=4",key:"cmgchess"}],frontMatter:{slug:"Prompt_Engineering",title:"Prompt Engineering",authors:"cmgchess",tags:["PromptEngineering"]},prevItem:{title:"Understanding Language Model Prompting",permalink:"/cmcs-docs/blog/Understanding_Language_Model_Prompting"}},c={authorsImageUrls:[void 0]},p=[],l={toc:p},m="wrapper";function g(e){let{components:t,...n}=e;return(0,a.kt)(m,(0,r.Z)({},l,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The recent advances in language models have led to remarkable improvements in various NLP tasks, such as text generation, summarization, question answering, and sentiment analysis. However, even state-of-the-art language models like GPT-3 require massive amounts of training data and compute resources to achieve their impressive performance. In this context, prompt engineering is a promising approach that can significantly improve the efficiency and effectiveness of language models for specific tasks."),(0,a.kt)("p",null,"Prompt engineering involves designing effective prompts that can guide the language model to produce the desired output for a given task. There are two main types of prompts: prefix prompts and cloze prompts. Prefix prompts involve adding task-specific vectors to the input text and updating only the prefix during training. This approach has been used in various text generation and text classification tasks. Cloze prompts involve converting subject-relation-object triples or question-answer pairs into a cloze statement that can be used to query the language model."),(0,a.kt)("p",null,"Designing the best prompt for each task can be done manually or automatically. Manual template designing has been used in many studies, but it has some limitations, as inappropriate prompts can lead to lower performance or incomplete knowledge contained in the language model. Automated template designing can be done using discrete or continuous prompts. Discrete prompts involve defining a set of trigger tokens that can be learned using gradient-based search strategies. Continuous prompts involve optimizing continuous vectors that are prepended to the input text. This approach, called pre-fix tuning, has been used in various studies to optimize language models for specific tasks while keeping the pre-trained parameters frozen."),(0,a.kt)("p",null,"To sum up, prompt engineering is a promising approach to improve the performance of language models for specific tasks. Effective prompts can significantly reduce the training data and compute resources required to achieve state-of-the-art performance, while also enhancing the interpretability and transparency of language models. Further research is needed to explore the optimal prompt engineering methods for various NLP tasks and to develop automated methods for prompt template designing."))}g.isMDXComponent=!0}}]);